{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -----------------------------\n# 1. Imports\n# -----------------------------\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom tqdm import tqdm\n\n# -----------------------------\n# 2. Paths\n# -----------------------------\ndata_dir = \"/kaggle/input/skin-cancer-mnist-ham10000\"\nmetadata_path = os.path.join(data_dir, \"HAM10000_metadata.csv\")\nimage_folders = [\n    os.path.join(data_dir, \"HAM10000_images_part_1\"),\n    os.path.join(data_dir, \"HAM10000_images_part_2\")\n]\nprint(\"Files in data directory:\", os.listdir(data_dir))\n\n# -----------------------------\n# 3. Load Dataset\n# -----------------------------\ndef load_dataset(metadata_path, test_size=0.2, random_state=42):\n    labels_df = pd.read_csv(metadata_path)\n    label_map = {cls:i for i, cls in enumerate(labels_df['dx'].unique())}\n    labels_df['label'] = labels_df['dx'].map(label_map)\n    train_df, test_df = train_test_split(labels_df, test_size=test_size, stratify=labels_df['label'], random_state=random_state)\n    return train_df, test_df, label_map\n\ntrain_df, test_df, label_map = load_dataset(metadata_path)\nprint(f\"Number of classes: {len(label_map)}\")\n\n# -----------------------------\n# 4. Dataset Class\n# -----------------------------\nclass HAM10000Dataset(Dataset):\n    def __init__(self, df, data_dirs, transform=None):\n        self.df = df.reset_index(drop=True)\n        if isinstance(data_dirs, str):\n            self.data_dirs = [data_dirs]\n        else:\n            self.data_dirs = data_dirs\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = self.df.loc[idx, 'image_id'] + '.jpg'\n        img_path = None\n        for folder in self.data_dirs:\n            candidate = os.path.join(folder, img_name)\n            if os.path.exists(candidate):\n                img_path = candidate\n                break\n        if img_path is None:\n            raise FileNotFoundError(f\"{img_name} not found in any folder\")\n        image = Image.open(img_path).convert('RGB')\n        label = self.df.loc[idx, 'label']\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# -----------------------------\n# 5. Transformations\n# -----------------------------\ntrain_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\ntrain_dataset = HAM10000Dataset(train_df, data_dirs=image_folders, transform=train_transform)\ntest_dataset = HAM10000Dataset(test_df, data_dirs=image_folders, transform=test_transform)\n\n# -----------------------------\n# 6. DataLoaders\n# -----------------------------\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# -----------------------------\n# 7. Train T-ResNet50 Classifier\n# -----------------------------\ndef train_classifier(train_loader, n_classes, device='cuda', n_epochs=20):\n    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n    model.fc = nn.Sequential(\n        nn.Linear(model.fc.in_features, 128),\n        nn.ReLU(),\n        nn.Linear(128, n_classes)\n    )\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    criterion = nn.CrossEntropyLoss()\n    \n    for epoch in range(n_epochs):\n        model.train()\n        running_loss = 0\n        for imgs, labels in tqdm(train_loader):\n            imgs, labels = imgs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f\"Epoch [{epoch+1}/{n_epochs}] | Loss: {running_loss/len(train_loader):.4f}\")\n    return model\n\nn_classes = len(label_map)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = train_classifier(train_loader, n_classes, device=device, n_epochs=20)\n\n# -----------------------------\n# 8. Evaluation\n# -----------------------------\ndef evaluate_model(model, loader, device='cuda'):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            preds = torch.argmax(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    acc = accuracy_score(all_labels, all_preds)\n    prec = precision_score(all_labels, all_preds, average='macro')\n    rec = recall_score(all_labels, all_preds, average='macro')\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    cm = confusion_matrix(all_labels, all_preds)\n    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n    print(\"Confusion Matrix:\\n\", cm)\n\nevaluate_model(model, test_loader, device=device)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:35:46.617696Z","iopub.execute_input":"2025-11-23T11:35:46.618509Z","iopub.status.idle":"2025-11-23T12:14:45.314082Z","shell.execute_reply.started":"2025-11-23T11:35:46.618479Z","shell.execute_reply":"2025-11-23T12:14:45.313197Z"}},"outputs":[{"name":"stdout","text":"Files in data directory: ['hmnist_8_8_RGB.csv', 'hmnist_28_28_RGB.csv', 'HAM10000_images_part_1', 'ham10000_images_part_1', 'hmnist_8_8_L.csv', 'HAM10000_images_part_2', 'ham10000_images_part_2', 'hmnist_28_28_L.csv', 'HAM10000_metadata.csv']\nNumber of classes: 7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20] | Loss: 0.7155\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:56<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/20] | Loss: 0.5120\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/20] | Loss: 0.4252\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:56<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/20] | Loss: 0.3660\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:58<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/20] | Loss: 0.3149\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:59<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/20] | Loss: 0.2762\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/20] | Loss: 0.2466\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:56<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/20] | Loss: 0.1990\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/20] | Loss: 0.1702\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/20] | Loss: 0.1625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:56<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/20] | Loss: 0.1370\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:56<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/20] | Loss: 0.1326\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/20] | Loss: 0.1235\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:54<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/20] | Loss: 0.1098\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:54<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/20] | Loss: 0.1045\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:56<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/20] | Loss: 0.0927\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:54<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/20] | Loss: 0.0750\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/20] | Loss: 0.0741\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:55<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [19/20] | Loss: 0.0739\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 251/251 [01:54<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [20/20] | Loss: 0.0743\nAccuracy: 0.8857, Precision: 0.8310, Recall: 0.7422, F1: 0.7811\nConfusion Matrix:\n [[ 172   24    0   15    0    2    7]\n [  16 1296    1   23    0    5    0]\n [   1    6   14    1    0    1    0]\n [   7   64    1  148    0    2    1]\n [   0    3    0    1   22    2    0]\n [   2    8    1    2    0   86    4]\n [   9    6    2    5    0    7   36]]\n","output_type":"stream"}],"execution_count":4}]}